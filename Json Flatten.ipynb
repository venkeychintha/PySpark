{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e290b6da-ea3d-4964-a1d0-38d58cfbd1a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Employee</th></tr></thead><tbody><tr><td>List(List(Manager, List(List(List(List(ep, 46044403, 1, MP)), 46555002, 1)), 46066601), List(Supervisor, List(List(List(List(ep, 56044403, 1, MP), List(fs, 56044000, 0, D)), 5605501, 1)), 56555000))</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          [
           "Manager",
           [
            [
             [
              [
               "ep",
               46044403,
               1,
               "MP"
              ]
             ],
             46555002,
             1
            ]
           ],
           46066601
          ],
          [
           "Supervisor",
           [
            [
             [
              [
               "ep",
               56044403,
               1,
               "MP"
              ],
              [
               "fs",
               56044000,
               0,
               "D"
              ]
             ],
             5605501,
             1
            ]
           ],
           56555000
          ]
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Employee",
         "type": "{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"Destination\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"attribute\",\"type\":{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"Department\",\"type\":{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"Code\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Dept_id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"dept_flag\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"dept_type\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"Parent_id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"status_flag\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"emp_id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df = spark.read.option('multiline' 'true').json('dbfs:/FileStore/tables/Sample_data.json')\n",
    "\n",
    "# Read multiline json file\n",
    "df = spark.read.option(\"multiline\",\"true\") \\\n",
    "      .json(\"dbfs:/FileStore/tables/Sample_data.json\")    \n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f3fb10-2d46-4192-bf00-f289480b5b92",
     "showTitle": true,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##Define Python function to flatten deeply nested JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b69c4b47-8919-4991-bafc-4308d7b54a3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "#Flatten array of structs and structs\n",
    "def flatten(df):\n",
    "   # compute Complex Fields (Lists and Structs) in Schema   \n",
    "   complex_fields = dict([(field.name, field.dataType)\n",
    "                             for field in df.schema.fields\n",
    "                             if type(field.dataType) == ArrayType or  type(field.dataType) == StructType])\n",
    "   while len(complex_fields)!=0:\n",
    "      col_name=list(complex_fields.keys())[0]\n",
    "      print (\"Processing :\"+col_name+\" Type : \"+str(type(complex_fields[col_name])))\n",
    "    \n",
    "      # if StructType then convert all sub element to columns.\n",
    "      # i.e. flatten structs\n",
    "      if (type(complex_fields[col_name]) == StructType):\n",
    "         expanded = [col(col_name+'.'+k).alias(col_name+'_'+k) for k in [ n.name for n in  complex_fields[col_name]]]\n",
    "         df=df.select(\"*\", *expanded).drop(col_name)\n",
    "    \n",
    "      # if ArrayType then add the Array Elements as Rows using the explode function\n",
    "      # i.e. explode Arrays\n",
    "      elif (type(complex_fields[col_name]) == ArrayType):    \n",
    "         df=df.withColumn(col_name,explode_outer(col_name))\n",
    "    \n",
    "      # recompute remaining Complex Fields in Schema       \n",
    "      complex_fields = dict([(field.name, field.dataType)\n",
    "                             for field in df.schema.fields\n",
    "                             if type(field.dataType) == ArrayType or  type(field.dataType) == StructType])\n",
    "   return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b379c6ae-9d22-4ff0-bbca-6234175b9425",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing :Employee Type : <class 'pyspark.sql.types.ArrayType'>\nProcessing :Employee Type : <class 'pyspark.sql.types.StructType'>\nProcessing :Employee_attribute Type : <class 'pyspark.sql.types.ArrayType'>\nProcessing :Employee_attribute Type : <class 'pyspark.sql.types.StructType'>\nProcessing :Employee_attribute_Department Type : <class 'pyspark.sql.types.ArrayType'>\nProcessing :Employee_attribute_Department Type : <class 'pyspark.sql.types.StructType'>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Employee_Destination</th><th>Employee_emp_id</th><th>Employee_attribute_Parent_id</th><th>Employee_attribute_status_flag</th><th>Employee_attribute_Department_Code</th><th>Employee_attribute_Department_Dept_id</th><th>Employee_attribute_Department_dept_flag</th><th>Employee_attribute_Department_dept_type</th></tr></thead><tbody><tr><td>Manager</td><td>46066601</td><td>46555002</td><td>1</td><td>ep</td><td>46044403</td><td>1</td><td>MP</td></tr><tr><td>Supervisor</td><td>56555000</td><td>5605501</td><td>1</td><td>ep</td><td>56044403</td><td>1</td><td>MP</td></tr><tr><td>Supervisor</td><td>56555000</td><td>5605501</td><td>1</td><td>fs</td><td>56044000</td><td>0</td><td>D</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Manager",
         46066601,
         46555002,
         1,
         "ep",
         46044403,
         1,
         "MP"
        ],
        [
         "Supervisor",
         56555000,
         5605501,
         1,
         "ep",
         56044403,
         1,
         "MP"
        ],
        [
         "Supervisor",
         56555000,
         5605501,
         1,
         "fs",
         56044000,
         0,
         "D"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Employee_Destination",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Employee_emp_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee_attribute_Parent_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee_attribute_status_flag",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee_attribute_Department_Code",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Employee_attribute_Department_Dept_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee_attribute_Department_dept_flag",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee_attribute_Department_dept_type",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Applying Flattening Function and Display flattened data\n",
    "\n",
    "df_flatten = flatten(df)\n",
    "display(df_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a713e094-17a9-4d14-9810-000e23ea1d05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Json Flatten",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
